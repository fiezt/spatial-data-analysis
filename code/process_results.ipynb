{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'belltown_denny_results_5'\n",
    "path2 = 'belltown_commcore_results'\n",
    "path3 = 'belltown_commcore_results_6'\n",
    "path4 = 'belltown_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = os.path.join(os.getcwd(), '..', path1)\n",
    "path_2 = os.path.join(os.getcwd(), '..', path2)\n",
    "path_3 = os.path.join(os.getcwd(), '..', path3)\n",
    "path_4 = os.path.join(os.getcwd(), '..', path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_season_paths = ['fall_2016', 'spring_2017', 'summer_2016', 'summer_2017', 'winter_2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths1 = [os.path.join(path_1, path) for path in all_season_paths]\n",
    "paths2 = [os.path.join(path_2, path) for path in all_season_paths]\n",
    "paths3 = [os.path.join(path_3, path) for path in all_season_paths]\n",
    "paths4 = [os.path.join(path_4, path) for path in all_season_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path4_gmm_var = []\n",
    "path4_sdot_var = []\n",
    "\n",
    "path4_gmm_sd = []\n",
    "path4_sdot_sd = []\n",
    "\n",
    "for path in paths1:\n",
    "    gmm = pd.read_csv(os.path.join(path, 'gmm_var.csv'), header=None).values.mean()\n",
    "    sdot = pd.read_csv(os.path.join(path, 'sdot_var.csv'), header=None).values.mean()\n",
    "    \n",
    "    path4_gmm_var.append(gmm)\n",
    "    path4_sdot_var.append(sdot)\n",
    "    path4_gmm_sd.append(np.sqrt(gmm))\n",
    "    path4_sdot_sd.append(np.sqrt(sdot))\n",
    "\n",
    "path4_gmm_var = np.array(path4_gmm_var)\n",
    "path4_sdot_var = np.array(path4_sdot_var)\n",
    "path4_gmm_sd = np.array(path4_gmm_sd)\n",
    "path4_sdot_sd = np.array(path4_sdot_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM 5.8 6.0 6.2\n",
      "SDOT 9.0 9.5 10.1\n"
     ]
    }
   ],
   "source": [
    "print 'GMM', round(path4_gmm_var.min(), 3)*100, round(path4_gmm_var.mean(), 3)*100, round(path4_gmm_var.max(), 3)*100\n",
    "print 'SDOT', round(path4_sdot_var.min(), 3)*100, round(path4_sdot_var.mean(), 3)*100, round(path4_sdot_var.max(), 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM 24.1 24.5 24.9\n",
      "SDOT 29.9 30.7 31.8\n"
     ]
    }
   ],
   "source": [
    "print 'GMM', round(path4_gmm_sd.min(), 3)*100, round(path4_gmm_sd.mean(), 3)*100, round(path4_gmm_sd.max(), 3)*100\n",
    "print 'SDOT', round(path4_sdot_sd.min(), 3)*100, round(path4_sdot_sd.mean(), 3)*100, round(path4_sdot_sd.max(), 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1_consist = []\n",
    "for path in paths1:\n",
    "    test = pd.read_csv(os.path.join(path, 'consistencies.csv'))\n",
    "    path1_consist.append(round(test[test.columns[-1]].values[:-1].mean(), 1))\n",
    "\n",
    "path2_consist = []\n",
    "for path in paths2:\n",
    "    test = pd.read_csv(os.path.join(path, 'consistencies.csv'))\n",
    "    path2_consist.append(round(test[test.columns[-1]].values[:-1].mean(), 1))\n",
    "    \n",
    "path3_consist = []\n",
    "for path in paths3:\n",
    "    test = pd.read_csv(os.path.join(path, 'consistencies.csv'))\n",
    "    path3_consist.append(round(test[test.columns[-1]].values[:-1].mean(), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1_moran = []\n",
    "for path in paths1:\n",
    "    test = pd.read_csv(os.path.join(path, 'Moran_Results.csv')).iloc[2].values[1:].tolist()\n",
    "    path1_moran.append(test)\n",
    "    \n",
    "path1_moran = np.vstack((path1_moran)).mean(axis=0)\n",
    "\n",
    "path2_moran = []\n",
    "for path in paths2:\n",
    "    test = pd.read_csv(os.path.join(path, 'Moran_Results.csv')).iloc[2].values[1:].tolist()\n",
    "    path2_moran.append(test)\n",
    "    \n",
    "path2_moran = np.vstack((path2_moran)).mean(axis=0)\n",
    "\n",
    "path3_moran = []\n",
    "for path in paths3:\n",
    "    test = pd.read_csv(os.path.join(path, 'Moran_Results.csv')).iloc[2].values[1:].tolist()\n",
    "    path3_moran.append(test)\n",
    "    \n",
    "path3_moran = np.vstack((path3_moran)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denny\n",
      "80.9 & 81.9 & 83.0 & 83.0 & 82.8 & \n",
      "\n",
      "commcore\n",
      "79.5 & 82.6 & 81.7 & 83.2 & 80.1 & \n",
      "\n",
      "commcore_6\n",
      "75.7 & 78.7 & 78.5 & 79.8 & 76.5 &\n"
     ]
    }
   ],
   "source": [
    "print 'denny'\n",
    "for num in path1_consist:\n",
    "    print str(num) + ' &',     \n",
    "print '\\n'\n",
    "\n",
    "print 'commcore'\n",
    "for num in path2_consist:\n",
    "    print str(num) + ' &', \n",
    "print '\\n'\n",
    "\n",
    "print 'commcore_6'\n",
    "for num in path3_consist:\n",
    "    print str(num) + ' &', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denny\n",
      "98.4 & 98.3 & 89.1 & 88.8 & 1.4 & 1.7 & 1.0 & 1.7 & \n",
      "\n",
      "commcore\n",
      "99.7 & 99.5 & 88.0 & 87.6 & 9.0 & 14.0 & 10.9 & 9.0 & \n",
      "\n",
      "commcore_6\n",
      "99.9 & 99.8 & 88.0 & 87.6 & 9.0 & 14.0 & 10.9 & 9.0 &\n"
     ]
    }
   ],
   "source": [
    "print 'denny'\n",
    "for num in np.round(path1_moran, 1):\n",
    "    print str(num) + ' &', \n",
    "print '\\n'\n",
    "\n",
    "print 'commcore'\n",
    "for num in np.round(path2_moran, 1):\n",
    "    print str(num) + ' &', \n",
    "print '\\n'\n",
    "\n",
    "print 'commcore_6'\n",
    "for num in np.round(path3_moran, 1):\n",
    "    print str(num) + ' &', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly min: 83.0\n",
      "Hourly max: 90.2\n",
      "Daily Min 82.5\n",
      "Daily Max 87.3\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '..', 'belltown_results', 'summer_2017')\n",
    "\n",
    "# Without first hour.\n",
    "hourly_avg = np.round(pd.read_csv(os.path.join(path, \n",
    "                                    'consistencies.csv')).values[:-1, 2:-1].mean(axis=0).astype(float), 1)\n",
    "\n",
    "print 'Hourly min:', hourly_avg.min()\n",
    "print 'Hourly max:', hourly_avg.max()\n",
    "\n",
    "daily_avg = pd.read_csv(os.path.join(path, 'consistencies.csv')).values[:-1, 1:-1].mean(axis=1).astype(float)\n",
    "print 'Daily Min', np.round_(daily_avg.min(), 1)\n",
    "print 'Daily Max', np.round_(daily_avg.max(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summer 2016: 86.6\n",
      "Fall 2016: 83.9\n",
      "Winter 2017: 84.9\n",
      "Spring 2017: 85.8\n",
      "Summer 2017: 85.9\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '..', 'belltown_results', 'summer_2016')\n",
    "daily_avg = pd.read_csv(os.path.join(path, 'consistencies.csv')).values[:-1, 1:-1].mean(axis=1).astype(float)\n",
    "daily_avg = daily_avg.mean()\n",
    "print 'Summer 2016:', np.round_(daily_avg, 1)\n",
    "\n",
    "path = os.path.join(os.getcwd(), '..', 'belltown_results', 'fall_2016')\n",
    "daily_avg = pd.read_csv(os.path.join(path, 'consistencies.csv')).values[:-1, 1:-1].mean(axis=1).astype(float)\n",
    "daily_avg = daily_avg.mean()\n",
    "print 'Fall 2016:', np.round_(daily_avg, 1)\n",
    "\n",
    "path = os.path.join(os.getcwd(), '..', 'belltown_results', 'winter_2017')\n",
    "daily_avg = pd.read_csv(os.path.join(path, 'consistencies.csv')).values[:-1, 1:-1].mean(axis=1).astype(float)\n",
    "daily_avg = daily_avg.mean()\n",
    "print 'Winter 2017:', np.round_(daily_avg, 1)\n",
    "\n",
    "path = os.path.join(os.getcwd(), '..', 'belltown_results', 'spring_2017')\n",
    "daily_avg = pd.read_csv(os.path.join(path, 'consistencies.csv')).values[:-1, 1:-1].mean(axis=1).astype(float)\n",
    "daily_avg = daily_avg.mean()\n",
    "print 'Spring 2017:', np.round_(daily_avg, 1)\n",
    "\n",
    "path = os.path.join(os.getcwd(), '..', 'belltown_results', 'summer_2017')\n",
    "daily_avg = pd.read_csv(os.path.join(path, 'consistencies.csv')).values[:-1, 1:-1].mean(axis=1).astype(float)\n",
    "daily_avg = daily_avg.mean()\n",
    "print 'Summer 2017:', np.round_(daily_avg, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
