{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import utils\n",
    "import gmm\n",
    "import figure_functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "data_path = curr_dir + '/../data/'\n",
    "fig_path = curr_dir + '/../figs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "park_data, gps_loc, N = utils.load_daily_data(data_path)\n",
    "results = gmm.locational_demand_analysis(park_data, gps_loc, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(results, open('results.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = [result[0] for result in results]\n",
    "hours = [result[1] for result in results]\n",
    "errors = [result[2] for result in results]\n",
    "morans = [result[3] for result in results]\n",
    "means = [result[4] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for time in range(60):\n",
    "    data = np.vstack((means[time]))\n",
    "    kmeans = KMeans(n_clusters=4).fit(data)\n",
    "    labels = kmeans.labels_.tolist()\n",
    "    scores.append((time, kmeans.score(data)))\n",
    "    \n",
    "scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "times = [score[0] for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_times = []\n",
    "for time in times:\n",
    "    if time % 10 + 8 in [8,9]:\n",
    "        continue\n",
    "        \n",
    "    good_times.append(time)\n",
    "    data = np.vstack((means[time]))\n",
    "    kmeans = KMeans(n_clusters=4).fit(data)\n",
    "    labels = kmeans.labels_.tolist()\n",
    "    \n",
    "#     print 'Time index is', time\n",
    "\n",
    "#     print len(np.where(np.array(labels) == 0)[0])\n",
    "#     print len(np.where(np.array(labels) == 1)[0])\n",
    "#     print len(np.where(np.array(labels) == 2)[0])\n",
    "#     print len(np.where(np.array(labels) == 3)[0])\n",
    "\n",
    "    plt.figure(figsize=(18,16))\n",
    "\n",
    "    colors = {0: 'blue', 1: 'red', 2: 'green', 3: 'orange'}\n",
    "\n",
    "#     for i in range(len(labels)):\n",
    "#         plt.scatter(data[i,0], data[i,1], color=colors[labels[i]], s=100)\n",
    "#         plt.scatter(data[i,0], data[i,1], color=colors[labels[i]], s=100)\n",
    "#         plt.scatter(data[i,0], data[i,1], color=colors[labels[i]], s=100)\n",
    "#         plt.scatter(data[i,0], data[i,1], color=colors[labels[i]], s=100)\n",
    "#     plt.show()\n",
    "    \n",
    "    if len(good_times) == 12:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "fig, ax = figure_functions.centroid_plots(means, gps_loc, N, times=good_times, fig_path=fig_path, shape=(3,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "\n",
    "n = len(data)\n",
    "\n",
    "# Seed numpy random number generator.\n",
    "np.random.seed()\n",
    "\n",
    "# Choosing the first cluster centroid uniformly at random.\n",
    "init = np.random.choice(range(n), 1, replace=False).tolist()\n",
    "means = data[init]\n",
    "\n",
    "# Choosing the rest of the cluster centroid initializations.\n",
    "for i in range(1, k):\n",
    "\n",
    "    # Finding minimum squared distance for each point to an existing center.\n",
    "    squared_dists = np.array([[np.linalg.norm(data[j]-means[l])**2 \n",
    "                             for l in xrange(i)] for j in xrange(n)])\n",
    "\n",
    "    dist_mins = squared_dists.min(axis=1)\n",
    "\n",
    "    # Sampling with probability proportional to the minimum squared distance.\n",
    "    prob_weights = dist_mins/dist_mins.sum()\n",
    "    sample = np.random.multinomial(1, prob_weights).tolist()\n",
    "    sample_choice = sample.index(1)\n",
    "\n",
    "    means = np.vstack((means, data[sample_choice]))\n",
    "    \n",
    "\n",
    "squared_dists = np.array([[np.linalg.norm(data[j]-means[l])**2 \n",
    "                             for l in xrange(k)] for j in xrange(n)])\n",
    "min_max = abs(squared_dists.min(axis=1) - squared_dists.max(axis=1))\n",
    "min_max = min_max.reshape((-1, 1))\n",
    "min_max = np.hstack((min_max, np.arange(len(min_max)).reshape((-1,1))))\n",
    "min_max = min_max[min_max[:,0].argsort()][::-1]\n",
    "preferences = np.argmin(squared_dists, axis=1)\n",
    "old_labels = np.nan * np.zeros(n)\n",
    "\n",
    "removed_labels = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in xrange(n):\n",
    "    \n",
    "    while True:\n",
    "        if np.isnan(old_labels[int(min_max[count,1])]):\n",
    "            \n",
    "            old_labels[int(min_max[count,1])] = preferences[int(min_max[count,1])]\n",
    "        \n",
    "            count += 1\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "    \n",
    "    for j in xrange(k):\n",
    "                \n",
    "        if list(old_labels).count(j) == n/k and j not in removed_labels:\n",
    "            \n",
    "            removed_labels.append(j)\n",
    "            \n",
    "            if len(removed_labels) == k:\n",
    "                break\n",
    "            \n",
    "            squared_dists = np.array([[np.linalg.norm(data[m] - means[l])**2 \n",
    "                                       for l in xrange(k)] for m in xrange(n)])\n",
    "            \n",
    "            squared_dists[:, removed_labels] = np.nan\n",
    "            \n",
    "            min_max = abs(np.nanmin(squared_dists, axis=1) - np.nanmax(squared_dists, axis=1))\n",
    "            \n",
    "            min_max = min_max.reshape((-1, 1))\n",
    "            \n",
    "            min_max = np.hstack((min_max, np.arange(len(min_max)).reshape((-1,1))))\n",
    "            \n",
    "            min_max = min_max[min_max[:,0].argsort()][::-1]\n",
    "            \n",
    "            preferences = np.nanargmin(squared_dists, axis=1)\n",
    "                        \n",
    "            count = 0\n",
    "            \n",
    "            break\n",
    "            \n",
    "plt.figure(figsize=(18,16))\n",
    "\n",
    "colors = {0: 'blue', 1: 'red', 2: 'green', 3: 'orange'}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    plt.scatter(data[i,0], data[i,1], color=colors[old_labels[i]], s=100)\n",
    "    plt.scatter(data[i,0], data[i,1], color=colors[old_labels[i]], s=100)\n",
    "    plt.scatter(data[i,0], data[i,1], color=colors[old_labels[i]], s=100)\n",
    "    plt.scatter(data[i,0], data[i,1], color=colors[old_labels[i]], s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_converged = True\n",
    "\n",
    "while not_converged:\n",
    "    means = np.array([data[np.where(old_labels == i)[0]].mean(axis=0).tolist() \n",
    "                      for i in xrange(k)])  \n",
    "    \n",
    "    new_squared_dists = np.array([[np.linalg.norm(data[j]-means[l])**2 \n",
    "                             for l in xrange(k)] for j in xrange(n)])\n",
    "    \n",
    "    new_preferences = np.argmin(new_squared_dists, axis=1)\n",
    "    \n",
    "    \n",
    "    sorted_dists = np.fliplr(np.sort(new_squared_dists, axis=1))\n",
    "    \n",
    "    delta = abs(sorted_dists[:, 0, None] - sorted_dists[:, 1, None])\n",
    "\n",
    "    delta = np.hstack((delta, np.arange(n).reshape((-1,1))))\n",
    "            \n",
    "    delta = delta[delta[:, 0].argsort()][::-1]        \n",
    "    \n",
    "    changes = []\n",
    "    \n",
    "    for idx in delta[:,1]:\n",
    "        if new_preferences[int(idx)] != old_labels[int(idx)]:\n",
    "            changes.append([idx, old_labels[int(idx)], new_preferences[int(idx)]])\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_squared_dists[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
