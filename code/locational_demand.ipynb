{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import pickle\n",
    "import utils\n",
    "import moran_auto\n",
    "import gmm\n",
    "import gmm3\n",
    "import kmeans_utils\n",
    "import figure_functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "data_path = curr_dir + '/../data/'\n",
    "fig_path = curr_dir + '/../figs/'\n",
    "results_path = curr_dir + '/../results'\n",
    "animation_path = curr_dir + '/../animation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = utils.load_data(data_path)\n",
    "gps_loc, avg_loads, park_data, N, P, idx_to_day_hour, day_hour_to_idx = params\n",
    "park_data_new = utils.load_daily_data(park_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gmm3.locational_demand_analysis(park_data_new, gps_loc, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [result[0] for result in results]\n",
    "hours = [result[1] for result in results]\n",
    "errors = [result[2] for result in results]\n",
    "means = [result[3] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Load</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">2015-01-05 08:00:00</th>\n",
       "      <th>1017</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.035056</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.083241</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.089618</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.421007</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>0.147917</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>0.056694</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>0.081694</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>0.127153</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>0.100139</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>0.023333</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>0.248272</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>0.041632</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>0.214653</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7257</th>\n",
       "      <td>0.113687</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7258</th>\n",
       "      <td>0.012799</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>0.086667</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>0.183294</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>0.133472</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">2015-04-06 08:00:00</th>\n",
       "      <th>77222</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77225</th>\n",
       "      <td>0.247738</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77226</th>\n",
       "      <td>0.372407</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77349</th>\n",
       "      <td>0.107262</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77569</th>\n",
       "      <td>0.006019</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570</th>\n",
       "      <td>0.156977</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77573</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77574</th>\n",
       "      <td>0.229921</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78041</th>\n",
       "      <td>0.124136</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78042</th>\n",
       "      <td>0.083287</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78117</th>\n",
       "      <td>0.131417</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78118</th>\n",
       "      <td>0.124722</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78122</th>\n",
       "      <td>0.153580</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79354</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79358</th>\n",
       "      <td>0.020401</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80881</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80882</th>\n",
       "      <td>0.168819</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81065</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81066</th>\n",
       "      <td>0.320185</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81289</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81290</th>\n",
       "      <td>0.081869</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81293</th>\n",
       "      <td>0.252540</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81294</th>\n",
       "      <td>0.425139</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81297</th>\n",
       "      <td>0.083272</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81342</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81453</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81454</th>\n",
       "      <td>0.198111</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81481</th>\n",
       "      <td>0.031594</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81482</th>\n",
       "      <td>0.050046</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121921</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3072 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Load        Date  Hour  Day\n",
       "Datetime            ID                                     \n",
       "2015-01-05 08:00:00 1017    0.000000  2015-01-05     8    0\n",
       "                    1018    0.000000  2015-01-05     8    0\n",
       "                    1021    0.035056  2015-01-05     8    0\n",
       "                    1022    0.000000  2015-01-05     8    0\n",
       "                    1025    0.083241  2015-01-05     8    0\n",
       "                    1026    0.000000  2015-01-05     8    0\n",
       "                    1029    0.089618  2015-01-05     8    0\n",
       "                    1030    0.421007  2015-01-05     8    0\n",
       "                    1033    0.000000  2015-01-05     8    0\n",
       "                    1034    0.000000  2015-01-05     8    0\n",
       "                    2781    0.147917  2015-01-05     8    0\n",
       "                    2782    0.000000  2015-01-05     8    0\n",
       "                    2785    0.056694  2015-01-05     8    0\n",
       "                    2786    0.000000  2015-01-05     8    0\n",
       "                    2789    0.081694  2015-01-05     8    0\n",
       "                    2790    0.127153  2015-01-05     8    0\n",
       "                    4433    0.100139  2015-01-05     8    0\n",
       "                    4434    0.000000  2015-01-05     8    0\n",
       "                    4437    0.023333  2015-01-05     8    0\n",
       "                    4438    0.248272  2015-01-05     8    0\n",
       "                    4441    0.041632  2015-01-05     8    0\n",
       "                    4442    0.000000  2015-01-05     8    0\n",
       "                    6197    0.214653  2015-01-05     8    0\n",
       "                    6198    0.000000  2015-01-05     8    0\n",
       "                    7257    0.113687  2015-01-05     8    0\n",
       "                    7258    0.012799  2015-01-05     8    0\n",
       "                    7261    0.086667  2015-01-05     8    0\n",
       "                    7262    0.183294  2015-01-05     8    0\n",
       "                    7265    0.133472  2015-01-05     8    0\n",
       "                    7266    0.000000  2015-01-05     8    0\n",
       "...                              ...         ...   ...  ...\n",
       "2015-04-06 08:00:00 77222   0.085714  2015-04-06     8    0\n",
       "                    77225   0.247738  2015-04-06     8    0\n",
       "                    77226   0.372407  2015-04-06     8    0\n",
       "                    77349   0.107262  2015-04-06     8    0\n",
       "                    77569   0.006019  2015-04-06     8    0\n",
       "                    77570   0.156977  2015-04-06     8    0\n",
       "                    77573   0.000000  2015-04-06     8    0\n",
       "                    77574   0.229921  2015-04-06     8    0\n",
       "                    78041   0.124136  2015-04-06     8    0\n",
       "                    78042   0.083287  2015-04-06     8    0\n",
       "                    78117   0.131417  2015-04-06     8    0\n",
       "                    78118   0.124722  2015-04-06     8    0\n",
       "                    78122   0.153580  2015-04-06     8    0\n",
       "                    79354   0.000000  2015-04-06     8    0\n",
       "                    79358   0.020401  2015-04-06     8    0\n",
       "                    80881   0.000000  2015-04-06     8    0\n",
       "                    80882   0.168819  2015-04-06     8    0\n",
       "                    81065   0.000000  2015-04-06     8    0\n",
       "                    81066   0.320185  2015-04-06     8    0\n",
       "                    81289   0.000000  2015-04-06     8    0\n",
       "                    81290   0.081869  2015-04-06     8    0\n",
       "                    81293   0.252540  2015-04-06     8    0\n",
       "                    81294   0.425139  2015-04-06     8    0\n",
       "                    81297   0.083272  2015-04-06     8    0\n",
       "                    81342   0.000000  2015-04-06     8    0\n",
       "                    81453   0.000000  2015-04-06     8    0\n",
       "                    81454   0.198111  2015-04-06     8    0\n",
       "                    81481   0.031594  2015-04-06     8    0\n",
       "                    81482   0.050046  2015-04-06     8    0\n",
       "                    121921  0.027778  2015-04-06     8    0\n",
       "\n",
       "[3072 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = park_data_new.loc[(park_data_new['Day'] == 0) & (park_data_new['Hour'] == 8)]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_df['Load'].values.reshape((N, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11368687,  0.01279915,  0.08666667,  0.18329365,  0.13347222,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.04650794,\n",
       "        0.00211806,  0.08326389])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03505556,  0.07502778,  0.04002778,  0.09002778,  0.1       ,\n",
       "        0.18675   ,  0.05666667,  0.07672222,  0.06497222,  0.14838889,\n",
       "        0.01005556,  0.09841667])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Load'].xs(1021, level=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df['Load'].values.reshape((-1, N)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03505556,  0.07502778,  0.04002778,  0.09002778,  0.1       ,\n",
       "        0.18675   ,  0.05666667,  0.07672222,  0.06497222,  0.14838889,\n",
       "        0.01005556,  0.09841667])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = [result[0] for result in results]\n",
    "hours = [result[1] for result in results]\n",
    "errors = [result[2] for result in results]\n",
    "morans_mixture = [result[3] for result in results]\n",
    "morans_adjacent = [result[4] for result in results]\n",
    "means = [result[5] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(errors).reshape((6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = sorted(park_data_new['Day'].unique())\n",
    "hours = sorted(park_data_new['Hour'].unique())\n",
    "\n",
    "times = list(itertools.product(days, hours))\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = times[iteration]\n",
    "day = time[0]\n",
    "hour = time[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_data = park_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = park_data.loc[(park_data['Day'] == day) & (park_data['Hour'] == hour)]\n",
    "block_keys = sorted(data_df.index.get_level_values(1).unique().tolist())\n",
    "\n",
    "# Each row is an element key, and each column is a date.\n",
    "data = data_df['Load'].values.reshape((N, -1))\n",
    "\n",
    "P = data.shape[1]\n",
    "\n",
    "average_accuracies = []\n",
    "\n",
    "centers = []\n",
    "\n",
    "morans_mixture = []\n",
    "morans_adjacent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model for each date for the given day and hour combination.\n",
    "for train_time in xrange(P):\n",
    "\n",
    "    train = np.hstack((data[:, train_time, None], gps_loc))\n",
    "\n",
    "    # Saving the scaling so it can be applied to the test set as well.\n",
    "    unscaled_loads = train[:,0]\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "    train = scaler.transform(train)\n",
    "\n",
    "    gmm = mixture.GaussianMixture(n_init=200, n_components=4, \n",
    "                                  covariance_type='diag').fit(train)\n",
    "\n",
    "    # Scaling the mean and covariances back to GPS coordinates.\n",
    "    means = np.vstack(([(mean[1:] - scaler.min_[1:])/(scaler.scale_[1:]) for mean in gmm.means_]))\n",
    "    covs = np.dstack(([np.diag((cov[1:])/(scaler.scale_[1:]**2)) for cov in gmm.covariances_])).T\n",
    "\n",
    "    centers.append(means)\n",
    "\n",
    "    train_labels = gmm.predict(train)\n",
    "\n",
    "    weights = moran_auto.get_mixture_weights(train_labels, N)        \n",
    "    I = moran_auto.moran_mixture(unscaled_loads, train_labels, N)\n",
    "    expectation = moran_auto.moran_expectation(N)\n",
    "    variance = moran_auto.moran_variance(unscaled_loads, weights, N)\n",
    "    z_score = moran_auto.z_score(I, expectation, variance)\n",
    "    p_one_sided, p_two_sided = moran_auto.p_value(z_score)\n",
    "\n",
    "    morans_mixture.append([I, expectation, variance, z_score, p_one_sided, p_two_sided])\n",
    "\n",
    "    weights = moran_auto.get_adjacent_weights(block_keys, N)        \n",
    "    I = moran_auto.moran_adjacent(unscaled_loads, block_keys, N)\n",
    "    expectation = moran_auto.moran_expectation(N)\n",
    "    variance = moran_auto.moran_variance(unscaled_loads, weights, N)\n",
    "    z_score = moran_auto.z_score(I, expectation, variance)\n",
    "    p_one_sided, p_two_sided = moran_auto.p_value(z_score)\n",
    "\n",
    "    morans_adjacent.append([I, expectation, variance, z_score, p_one_sided, p_two_sided])\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # For each other day of data, predict using model that was fit.\n",
    "    for test_time in xrange(P):\n",
    "\n",
    "        if test_time == train_time:\n",
    "            continue\n",
    "\n",
    "        test = np.hstack((data[:, test_time, None], gps_loc))\n",
    "\n",
    "        test = scaler.transform(test)\n",
    "\n",
    "        test_labels = gmm.predict(test)\n",
    "\n",
    "        correct_idx = [i for i in range(N) if train_labels[i] == test_labels[i]]\n",
    "        accuracy = len(correct_idx)/float(N)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    print accuracies\n",
    "    \n",
    "    \n",
    "    # Getting average prediction accuracy over all test sets.\n",
    "    average_accuracies.append(np.array(accuracies).mean())\n",
    "    print('These are average')\n",
    "    print average_accuracies\n",
    "\n",
    "# # Average error for the particular day and hour combination.\n",
    "# time_avg_accuracy = round(100.0 - np.array(average_accuracies).mean() * 100, 2)\n",
    "\n",
    "# result = (day, hour, time_avg_accuracy, morans_mixture, morans_adjacent, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure_functions.model_selection(avg_loads, gps_loc, P, fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_functions.create_animation(avg_loads, gps_loc, N, P, fig_path, animation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loads.mean(axis=1).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figure_functions.spatial_heterogeneity(loads=avg_loads, time=1, \n",
    "                                                 N=N, fig_path=fig_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figure_functions.mixture_plot(loads=avg_loads, gps_loc=gps_loc, \n",
    "                                        times=[time2], N=N, fig_path=fig_path, \n",
    "                                        shape=(1,1), filename='friday_6pm_gmm.png',\n",
    "                                        title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 2\n",
    "time1 = 2\n",
    "time2 = 9\n",
    "\n",
    "\n",
    "fig, ax = figure_functions.mixture_plot(loads=avg_loads, gps_loc=gps_loc, \n",
    "                                        times=[time1], N=N, fig_path=fig_path, \n",
    "                                        shape=(1,1), filename='friday_10am_gmm.png',\n",
    "                                        title='')\n",
    "fig, ax = figure_functions.mixture_plot(loads=avg_loads, gps_loc=gps_loc, \n",
    "                                        times=[time2], N=N, fig_path=fig_path, \n",
    "                                        shape=(1,1), filename='friday_6pm_gmm.png',\n",
    "                                        title='')\n",
    "\n",
    "fig, ax = figure_functions.interpolation(loads=avg_loads, gps_loc=gps_loc, time=time,\n",
    "                                         N=N, fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.triangular_grid(loads=avg_loads, gps_loc=gps_loc, time=time,\n",
    "                                           N=N, fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.contour_plot(loads=avg_loads, gps_loc=gps_loc, time=time1,\n",
    "                                        title='Friday 10:00 AM Average Load Contours', \n",
    "                                        N=N, filename='friday_10am.png', fig_path=fig_path, \n",
    "                                        contours=10)\n",
    "\n",
    "fig, ax = figure_functions.contour_plot(loads=avg_loads, gps_loc=gps_loc, time=time2,\n",
    "                                        title='Friday 6:00 PM Average Load Contours', \n",
    "                                        N=N, filename='friday_6pm.png', fig_path=fig_path, \n",
    "                                        contours=10)\n",
    "\n",
    "fig, ax = figure_functions.surface_plot(loads=avg_loads, gps_loc=gps_loc, time=time, \n",
    "                                        fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.voronoi(gps_loc=gps_loc, N=N, fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.spatial_heterogeneity(loads=avg_loads, time=time, \n",
    "                                                 N=N, fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.temporal_heterogeneity(loads=avg_loads, time=time, \n",
    "                                                  P=P, fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.temporal_day_plots(loads=avg_loads, P=P, fig_path=fig_path)\n",
    "\n",
    "fig, ax = figure_functions.temporal_hour_plots(loads=avg_loads, fig_path=fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time = times[iter]\n",
    "day = time[0]\n",
    "hour = time[1]\n",
    "\n",
    "data_df = park_data.loc[(park_data['Day'] == day) & (park_data['Hour'] == hour)]\n",
    "block_keys = sorted(data_df.index.get_level_values(1).unique().tolist())\n",
    "\n",
    "# Each row is an element key, and each column is a date.\n",
    "data = data_df['Load'].values.reshape((N, -1))\n",
    "\n",
    "P = data.shape[1]\n",
    "\n",
    "average_accuracies = []\n",
    "\n",
    "centers = []\n",
    "\n",
    "morans_mixture = []\n",
    "morans_adjacent = []\n",
    "\n",
    "# Fitting the model for each date for the given day and hour combination.\n",
    "for train_time in xrange(P):\n",
    "\n",
    "    train = np.hstack((data[:, train_time, None], gps_loc))\n",
    "\n",
    "    # Saving the scaling so it can be applied to the test set as well.\n",
    "    unscaled_loads = train[:,0]\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "    train = scaler.transform(train)\n",
    "\n",
    "    gmm = mixture.GaussianMixture(n_init=200, n_components=4, \n",
    "                                  covariance_type='diag').fit(train)\n",
    "\n",
    "    # Scaling the mean and covariances back to GPS coordinates.\n",
    "    means = np.vstack(([(mean[1:] - scaler.min_[1:])/(scaler.scale_[1:]) for mean in gmm.means_]))\n",
    "    covs = np.dstack(([np.diag((cov[1:])/(scaler.scale_[1:]**2)) for cov in gmm.covariances_])).T\n",
    "\n",
    "    centers.append(means)\n",
    "\n",
    "    train_labels = gmm.predict(train)\n",
    "\n",
    "    weights = moran_auto.get_mixture_weights(train_labels, N)        \n",
    "    I = moran_auto.moran_mixture(unscaled_loads, train_labels, N)\n",
    "    expectation = moran_auto.moran_expectation(N)\n",
    "    variance = moran_auto.moran_variance(unscaled_loads, weights, N)\n",
    "    z_score = moran_auto.z_score(I, expectation, variance)\n",
    "    p_one_sided, p_two_sided = moran_auto.p_value(z_score)\n",
    "\n",
    "    morans_mixture.append([I, expectation, variance, z_score, p_one_sided, p_two_sided])\n",
    "\n",
    "    weights = moran_auto.get_adjacent_weights(block_keys, N)        \n",
    "    I = moran_auto.moran_adjacent(unscaled_loads, block_keys, N)\n",
    "    expectation = moran_auto.moran_expectation(N)\n",
    "    variance = moran_auto.moran_variance(unscaled_loads, weights, N)\n",
    "    z_score = moran_auto.z_score(I, expectation, variance)\n",
    "    p_one_sided, p_two_sided = moran_auto.p_value(z_score)\n",
    "\n",
    "    morans_adjacent.append([I, expectation, variance, z_score, p_one_sided, p_two_sided])\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # For each other day of data, predict using model that was fit.\n",
    "    for test_time in xrange(P):\n",
    "\n",
    "        if test_time == train_time:\n",
    "            continue\n",
    "\n",
    "        test = np.hstack((data[:, test_time, None], gps_loc))\n",
    "\n",
    "        test = scaler.transform(test)\n",
    "\n",
    "        test_labels = gmm.predict(test)\n",
    "\n",
    "        correct_idx = [i for i in range(N) if train_labels[i] == test_labels[i]]\n",
    "        accuracy = len(correct_idx)/float(N)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Getting average prediction accuracy over all test sets.\n",
    "    average_accuracies.append(np.array(accuracies).mean())\n",
    "\n",
    "# Average error for the particular day and hour combination.\n",
    "time_avg_accuracy = round(100.0 - np.array(average_accuracies).mean() * 100, 2)\n",
    "\n",
    "result = (day, hour, time_avg_accuracy, morans_mixture, morans_adjacent, centers)\n",
    "\n",
    "return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_data, gps_loc, N = utils.load_daily_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = np.array(sorted(park_data['Load'].values.tolist(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(check > 1.5)[0])/float(len(check)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(range(10), index=range(10), columns=['check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = gmm.locational_demand_analysis(park_data, gps_loc, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [result[0] for result in results]\n",
    "hours = [result[1] for result in results]\n",
    "errors = [result[2] for result in results]\n",
    "morans_mix = [result[3] for result in results]\n",
    "morans_adj = [result[4] for result in results]\n",
    "means = [result[5] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores, times = kmeans_utils.get_time_scores(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_times = {}\n",
    "best_days = {}\n",
    "for time in times:\n",
    "    day = time/12\n",
    "    hour = time%12 + 8\n",
    "    if hour not in best_times:\n",
    "        best_times[hour] = time\n",
    "    if day not in best_days and hour not in [8, 15,16,17]:\n",
    "        print day, hour\n",
    "        best_days[day] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_times = []\n",
    "\n",
    "for time in times:\n",
    "    if time % 12 + 8 in [8,9]:\n",
    "        continue\n",
    "        \n",
    "    good_times.append(time)\n",
    "    data = np.vstack((means[time]))\n",
    "    kmeans = KMeans(n_clusters=3).fit(data)\n",
    "    labels = kmeans.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_times = best_days.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figure_functions.centroid_plots(means, gps_loc, N, times=good_times, fig_path=fig_path, shape=(2,3))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
