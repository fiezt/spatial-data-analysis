{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import process_data\n",
    "import gmm\n",
    "import figure_functions\n",
    "import kmeans_utils\n",
    "import write_results\n",
    "import load_sdot_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "data_path = curr_dir + '/../data'\n",
    "animation_path = curr_dir + '/../animation'\n",
    "belltown_path = data_path + '/Belltown_Hour'\n",
    "dennytriangle_path = data_path + '/DennyTriangle_Hour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2016) (8, 2016)\n",
      "(9, 2016) (11, 2016)\n",
      "(12, 2016) (2, 2017)\n",
      "(3, 2017) (5, 2017)\n",
      "(6, 2017) (8, 2017)\n"
     ]
    }
   ],
   "source": [
    "path = [belltown_path, dennytriangle_path]\n",
    "\n",
    "all_loads = []\n",
    "all_element_keys = []\n",
    "all_gps = []\n",
    "all_park_data = []\n",
    "starts = [(6, 2016), (9, 2016), (12, 2016), (3, 2017), (6, 2017)]\n",
    "ends = [(8, 2016), (11, 2016), (2, 2017), (5, 2017), (8, 2017)]\n",
    "\n",
    "for pair in zip(starts, ends):\n",
    "    \n",
    "    month_year_start = pair[0]\n",
    "    month_year_end = pair[1]\n",
    "    \n",
    "    print month_year_start, month_year_end\n",
    "    \n",
    "    params = process_data.load_data(data_path=data_path, load_paths=path, \n",
    "                                    month_year_start=month_year_start, month_year_end=month_year_end, \n",
    "                                    verbose=False)\n",
    "    element_keys, loads, gps_loc, park_data, idx_to_day_hour, day_hour_to_idx = params\n",
    "        \n",
    "    all_element_keys.append(element_keys)\n",
    "    all_loads.append(loads)\n",
    "    all_gps.append(gps_loc)\n",
    "    all_park_data.append(park_data)    \n",
    "\n",
    "all_keys_seasonal = all_element_keys \n",
    "all_gps_seasonal = all_gps\n",
    "all_loads_seasonal = all_loads\n",
    "all_park_data_seasonal = all_park_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = os.path.join(curr_dir, '..', 'belltown_denny_figs_5')\n",
    "fig_paths_seasonal = []\n",
    "fig_paths_seasonal.append(os.path.join(fig_path, 'summer_2017'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [range(i, i+10) for i in xrange(0, 72, 12)]\n",
    "good_idx = [item for sublist in good_idx for item in sublist]\n",
    "\n",
    "for i in xrange(len(all_loads_seasonal)):\n",
    "    all_loads_seasonal[i] = all_loads_seasonal[i][:, good_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(len(all_park_data_seasonal)):\n",
    "    all_park_data_seasonal[i] = all_park_data_seasonal[i].loc[all_park_data_seasonal[i]['Hour'] < 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comps = 5\n",
    "time1 = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_functions.mixture_plot(all_loads_seasonal[-1], all_gps_seasonal[-1], time1, \n",
    "                              fig_paths_seasonal[-1], \n",
    "                              filename='mixture_belltown_denny.png',\n",
    "                              num_comps=num_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 5, 10]\n",
    "p_value = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = os.path.join(curr_dir, '..', 'belltown_denny_results_5')\n",
    "results_paths_seasonal = []\n",
    "results_paths_seasonal.append(os.path.join(results_path, 'summer_2016'))\n",
    "results_paths_seasonal.append(os.path.join(results_path, 'fall_2016'))\n",
    "results_paths_seasonal.append(os.path.join(results_path, 'winter_2017'))\n",
    "results_paths_seasonal.append(os.path.join(results_path, 'spring_2017'))\n",
    "results_paths_seasonal.append(os.path.join(results_path, 'summer_2017'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031.11650085\n",
      "1102.28839207\n",
      "946.595900059\n"
     ]
    }
   ],
   "source": [
    "area_map = pickle.load(open(os.path.join(data_path, 'belltown_denny_subareas.p'), 'rb'))\n",
    "\n",
    "for i in xrange(2, len(results_paths_seasonal)):\n",
    "    start = time.time()\n",
    "    results = gmm.locational_demand_analysis(all_park_data_seasonal[i], \n",
    "                                             all_gps_seasonal[i],\n",
    "                                             num_comps, k_values, area_map, verbose=False)\n",
    "    end = time.time()\n",
    "    \n",
    "    print end - start\n",
    "    \n",
    "    days = [result[0] for result in results]\n",
    "    hours = [result[1] for result in results]\n",
    "    \n",
    "    time_avg_consistency = [result[2] for result in results]\n",
    "    \n",
    "    write_results.write_gmm_results(time_avg_consistency, results_paths_seasonal[i])\n",
    "    \n",
    "    morans_mixture = [result[3] for result in results] \n",
    "    morans_dist_mixture = [result[4] for result in results] \n",
    "\n",
    "    morans_area = [result[5] for result in results]\n",
    "    morans_dist_area = [result[6] for result in results]\n",
    "\n",
    "    morans_dist = [result[7] for result in results]\n",
    "\n",
    "    morans_neighbor = [result[8] for result in results]\n",
    "\n",
    "    morans_3 = [neighbor[3] for neighbor in morans_neighbor]\n",
    "    morans_5 = [neighbor[5] for neighbor in morans_neighbor]\n",
    "    morans_10 = [neighbor[10] for neighbor in morans_neighbor]\n",
    "\n",
    "    gmm_var = [result[9] for result in results]\n",
    "    np.savetxt(os.path.join(results_paths_seasonal[i], 'gmm_var.csv'), np.array(gmm_var), delimiter=',')\n",
    "    \n",
    "    sdot_var = [result[10] for result in results]\n",
    "    np.savetxt(os.path.join(results_paths_seasonal[i], 'sdot_var.csv'), np.array(sdot_var), delimiter=',')\n",
    "    \n",
    "    centers = [result[11] for result in results]\n",
    "    \n",
    "    distances, centroids = kmeans_utils.get_distances(centers=centers, num_comps=num_comps)\n",
    "    best_time = distances.mean(axis=1).argmin()\n",
    "    \n",
    "    write_results.write_centroid_distance_results(days=days, hours=hours,\n",
    "                                                  distances=distances,\n",
    "                                                  results_path=results_paths_seasonal[i])\n",
    "    \n",
    "    all_morans = [morans_mixture, morans_dist_mixture, morans_area, morans_dist_area, \n",
    "              morans_dist, morans_3, morans_5, morans_10]\n",
    "    \n",
    "    auto_names = ['mixture', 'mixture_dist', 'area', 'area_dist', 'dist', 'k_3', 'k_5', 'k_10']\n",
    "    \n",
    "    all_I = []\n",
    "    all_p_one = []\n",
    "    all_p_two = []\n",
    "    \n",
    "    for j in xrange(len(auto_names)):\n",
    "        \n",
    "        results_path = os.path.join(results_paths_seasonal[i], auto_names[j])\n",
    "\n",
    "        I_avg, p_one_side, p_two_side = write_results.write_moran_results(days, hours, \n",
    "                                                                         all_morans[j], \n",
    "                                                                         p_value, results_path)\n",
    "        all_I.append(I_avg)\n",
    "        all_p_one.append(p_one_side)\n",
    "        all_p_two.append(p_two_side)\n",
    "    \n",
    "    avg_moran = np.vstack((all_I, all_p_one, all_p_two))\n",
    "    index = ['Moran I Over All Days and Times', \n",
    "             'Significant One Sided P Value Percentage Average Over All Days And Times', \n",
    "             'Significant Two Sided P Value Percentage Average Over All Days And Times']\n",
    "    avg_df = pd.DataFrame(avg_moran, index=index, columns=auto_names)\n",
    "    avg_df.to_csv(os.path.join(results_paths_seasonal[i], 'Moran_Results.csv'), sep=',')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
